# AI-Recycle-System

## **ğŸ“Œ Overview**
This project enables **automatic detection and classification** of recyclable materials (plastic, aluminum, glass, paper, etc.) using **YOLOv8** for object detection and **EfficientNet** for classification. The system also includes a **self-learning mechanism** that collects new images for retraining and logs misclassified items.

---

## **ğŸ“Œ 1. Setup Instructions**

### **ğŸ”¹ Prerequisites**
Ensure you have Python installed and install the required libraries:
```bash
pip install torch tensorflow opencv-python ultralytics matplotlib albumentations scikit-learn
```

### **ğŸ”¹ Cloning the Repository**
```bash
git clone https://github.com/your-repo/recycle_ai.git
cd recycle_ai
```

---

## **ğŸ“Œ 2. Imported Libraries**

### **ğŸ”¹ General Libraries**
- `os`, `time`, `json`, `shutil`, `subprocess`, `cv2` (OpenCV), `numpy`

### **ğŸ”¹ Deep Learning Libraries**
- `torch`, `tensorflow`, `ultralytics`
- `tensorflow.keras.applications`, `tensorflow.keras.preprocessing.image`, `tensorflow.keras.layers`, `tensorflow.keras.models`

### **ğŸ”¹ Data Handling & Visualization**
- `matplotlib.pyplot`, `albumentations`, `sklearn.utils.class_weight`

---

## **ğŸ“Œ 3. Classes & Functions**

### **ğŸ”¹ `DatasetHandler` (Dataset Management)**
| Method | Description |
|--------|-------------|
| `visualize_dataset_distribution()` | Displays a **bar chart** of dataset class distribution |
| `augment_data(save_path)` | Performs **data augmentation** |

#### **ğŸ“Œ Example Usage**
```python
dataset = DatasetHandler("datasets/recyclables")
dataset.visualize_dataset_distribution()
dataset.augment_data("datasets/augmented")
```

---

### **ğŸ”¹ `YOLOModel` (Object Detection)**
| Method | Description |
|--------|-------------|
| `train(dataset_yaml, epochs, imgsz)` | Trains YOLOv8 on a dataset |
| `detect(image)` | Runs object detection on an image |

#### **ğŸ“Œ Example Usage**
```python
yolo = YOLOModel()
yolo.train("datasets/taco.yaml", epochs=50)
detections = yolo.detect("test_image.jpg")
```

---

### **ğŸ”¹ `EfficientNetModel` (Classification)**
| Method | Description |
|--------|-------------|
| `train(dataset_path, epochs)` | Trains EfficientNet classifier on dataset |
| `visualize_training(history)` | Plots **training loss & accuracy** |

#### **ğŸ“Œ Example Usage**
```python
classifier = EfficientNetModel(num_classes=4)
classifier.train("datasets/classification")
```

---

### **ğŸ”¹ `SelfLearningSystem` (Self-Improvement)**
| Method | Description |
|--------|-------------|
| `save_detected_image(frame, prediction)` | Saves detected images for future retraining |
| `log_misclassification(image_path, true_label, predicted_label)` | Logs misclassified items |

#### **ğŸ“Œ Example Usage**
```python
self_learning = SelfLearningSystem()
self_learning.save_detected_image(image, "plastic")
self_learning.log_misclassification("image.jpg", "plastic", "glass")
```

---

### **ğŸ”¹ `Deployment` (Model Deployment)**
| Method | Description |
|--------|-------------|
| `run()` | Runs real-time detection using a webcam |

#### **ğŸ“Œ Example Usage (Laptop)**
```python
deploy = Deployment(model_type="laptop")
deploy.run()
```

#### **ğŸ“Œ Example Usage (Edge Device)**
```python
deploy = Deployment(model_type="edge")
deploy.run()
```

---

## **ğŸ“Œ 4. Flutter Mobile App**
The project includes a **Flutter mobile app** that allows users to monitor and interact with the sorting bin remotely. The app connects via **WiFi/Bluetooth** to receive real-time detection results and send control commands.

### **ğŸ”¹ Features**
- ğŸ“¸ **Live camera feed** with detection results.
- ğŸ“Š **Sorting statistics & history**.
- ğŸ”„ **Manual override** to open/close the bin.
- ğŸŒ **Remote monitoring & control**.

### **ğŸ”¹ Setup Instructions**
1. Install Flutter: [Flutter Setup Guide](https://flutter.dev/docs/get-started/install)
2. Clone the mobile app repository:
```bash
git clone https://github.com/your-repo/recycle_ai_app.git
cd recycle_ai_app
flutter pub get
```
3. Run the app:
```bash
flutter run
```

### **ğŸ”¹ Example Usage**
```dart
// Connect to the sorting bin via WiFi
SortingBinController binController = SortingBinController(ip: "192.168.1.10");
binController.getLiveFeed();
```

---

## **ğŸ“Œ 5. How to Train & Deploy the Model**

### **ğŸ”¹ Training YOLOv8**
```python
from recycle_ai import YOLOModel

yolo = YOLOModel()
yolo.train("datasets/taco.yaml", epochs=50)
```

### **ğŸ”¹ Training EfficientNet Classifier**
```python
from recycle_ai import EfficientNetModel

classifier = EfficientNetModel(num_classes=4)
classifier.train("datasets/classification")
```

### **ğŸ”¹ Running Inference on Laptop**
```python
from recycle_ai import Deployment

deploy = Deployment(model_type="laptop")
deploy.run()
```

### **ğŸ”¹ Running Inference on Edge Device**
```python
deploy = Deployment(model_type="edge")
deploy.run()
```

---

## **ğŸ“Œ 6. Advanced Features**

### **ğŸ”¹ Self-Learning: Improve Model Over Time**
- The system **saves newly detected images** for future training.
- It **logs misclassifications** for dataset improvement.

```python
self_learning = SelfLearningSystem()
self_learning.save_detected_image(frame, "plastic")
self_learning.log_misclassification("image.jpg", "plastic", "glass")
```

### **ğŸ”¹ Data Augmentation for Better Performance**
```python
dataset = DatasetHandler("datasets/recyclables")
dataset.augment_data("datasets/augmented")
```

---

## **ğŸ“Œ 7. Summary**
âœ… **YOLOv8 for Object Detection** (Plastic, Aluminum, Paper, Glass)  
âœ… **EfficientNet for Classification** (Material Type)  
âœ… **Self-Improving AI** (Collects new data & learns over time)  
âœ… **Deployment on Laptop & Edge Devices**  
âœ… **Flutter Mobile App for Monitoring & Control**  
âœ… **Dataset Handling, Augmentation, and Visualization**  

---

## **ğŸ“Œ 8. Next Steps**
1. **Train the model on TACO dataset** (or custom dataset)  
2. **Deploy on an edge device (e.g., Raspberry Pi, Jetson Nano)**  
3. **Fine-tune with real-world collected data**  

This README provides **everything needed to train, test, and deploy the AI recycling system**. ğŸš€

